 #theory #theory-ml
 
---
### Энкодер и Декодер в Keras

В пакете Keras мы отдельно опишем кодер и декодер и уже на их основе сформируем общий автоэнкодер:

```python
input_img = Input(shape=(28, 28, 1))                # ЭНКОДЕР
x = Flatten()(input_img)
x = Dense(128, activation='relu')(x)
x = Dense(64, activation='relu')(x)
encoded = Dense(2, activation='linear')(x)

input_enc = Input(shape=(2,))                       # ДЕКОДЕР
d = Dense(64, activation='relu')(input_enc)
d = Dense(28*28, activation='sigmoid')(d)
decoded = Reshape((28, 28, 1))(d)

encoder = keras.Model(input_img, encoded, name="encoder")    # МОДЕЛЬ ЭНКОДЕРА
decoder = keras.Model(input_enc, decoded, name="decoder")    # МОДЕЛЬ ДЕКОДЕРА
autoencoder = keras.Model(input_img, decoder(encoder(input_img)), name="autoencoder")    # ОБЩАЯ МОДЕЛЬ ДЛЯ СОВМЕСТНОГО ОБУЧЕНИЯ

autoencoder.compile(optimizer='adam', loss='mean_squared_error')
autoencoder.fit(x_train, x_train, epochs=10, batch_size=64, shuffle=True)
```

Пропустим через энкодер тестовую выборку и отобразим полученный массив векторов скрытого состояния на плоскости:

```python
h = encoder.predict(x_test)
plt.scatter(h[:, 0], h[:, 1])
```

---

### Основная Проблематика Обычных Автоэнкодеров

В результате мы получили картину формирования **модельной области отображения** входного сигнала в пространство скрытого состояния.

#### Что отсюда следует?
- Если мы будем брать точки в пределах сформированной области, то скорее всего, на выходе декодера будут получаться осмысленные изображения цифр.
- Если же брать точку за пределами этой области, то очень вероятно получим какое-то неопределенное изображение.

#### Вытекающий недостаток автоэнкодеров в чистом виде
Мы не можем брать произвольные точки в области скрытого состояния, чтобы гарантированно получать осмысленные изображения.

---

### Вариационные Автоэнкодеры (VAE)

Они решают эту проблему тем, что их пространство состояний скрытого вектора более **компактное** и стремится представить **единую цельную область без существенных разделений**.

#### Задача VAE
Сформировать область точек скрытого пространства в соответствии с заданным законом распределения. Так мы будем понимать, как выбирать точки в скрытом пространстве для генерации новых полноценных изображений.

Часто выбирают нормальное (гауссовское) распределение, так как оно:
1. Наиболее просто с вычислительной точки зрения.
2. Имеет понятную, приемлемую форму.
3. Полностью определяется двумя параметрами: математическое ожидание и дисперсия.

---

### Наглядное Объяснение

1. Пусть у нас есть формируемое и желаемое распределения точек скрытого пространства.
   - \( W_g \) - исходно формируемое автоэнкодером в чистом виде.
   - \( W_n \) - желаемое распределение.

2. Задачей алгоритма обучения будет:
   - Точно воспроизвести входной сигнал.
   - Распределить точки скрытого пространства как можно ближе к \( W_n \).

3. **Дивергенция Кульбака-Лейблера** - критерий качества, который будет оценивать степень расхождения между этими двумя распределениями \( W_g \) и \( W_n \). (learn more: [https://habr.com/ru/post/484756/](https://habr.com/ru/post/484756/))

   Так как мы предполагаем, что оба распределения будут гауссовскими с независимыми величинами вектора скрытого состояния, то расстояние Кульбака-Лейблера для этого случая записывается относительно просто, по следующей формуле:

   \( D_{KL} = f(M_g, M_n, N_n, N_g) \), где:
   - \( M_g, M_n \) - ковариационные матрицы векторов скрытого состояния (векторы представлены в виде главной диагонали нулевой матрицы. Они же - дисперсия значений).
   - \( N_n, N_g \) - векторы математического ожидания.

4. Мера расхождения двух гауссовых распределений у нас есть, и эта мера зависит от векторов МО и дисперсии:
   - Кодер на выходе выдает не эти величины, а непосредственно вектор скрытого состояния \( h \).
   - Чтобы получить необходимые МО и дисперсию за место непосредственного вектора, для вычисления расстояния КЛ, кодер будет формировать не сам вектор \( h \), а векторы МО и дисперсии.
   - Здесь генератор НСВ (норм. случай. вел.) выдает величины с нулевым вектором МО и единичными дисперсиями. Поэтому, после поэлементного умножения на дисперсию и сложением с МО, получим вектор скрытого состояния с этими характеристиками: 
     \( h = N \times d + MO \).

5. Имея эти оценки, можно:
   1. Использовать меру Кульбака-Лейблера для определения соответствия текущего распределения заданному.
   2. А также еще один критерий (loss) для соответствия входного сигнала выходному (например, можно взять меру минимума среднего квадрата ошибок рассогласования).

   - Результирующий критерий будет равен их сумме: \( L = loss + D_{KL} \).

---

### Источник
Подробнее можно ознакомиться с оригинальным постом на [Habr](https://habr.com/ru/post/484756/).

[26.1. Пример ВАЭ](2.%20Theory/Машинное%20обучение/Дополнительно/26.1.%20Пример%20ВАЭ.md)
[26.2. Расширенный ВАЭ](2.%20Theory/Машинное%20обучение/Дополнительно/26.2.%20Расширенный%20ВАЭ.md)