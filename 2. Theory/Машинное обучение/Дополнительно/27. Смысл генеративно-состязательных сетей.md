 #theory #theory-ml
 
---
[25. Автоэнкодеры](2.%20Theory/Машинное%20обучение/Дополнительно/25.%20Автоэнкодеры.md)
[26. Вариационные автоэнкодеры](2.%20Theory/Машинное%20обучение/Дополнительно/26.%20Вариационные%20автоэнкодеры.md)

В предыдущих моделях сетей при использовании стандартных функций вычисления качества выходного сигнала результат выглядел размытым, т.о. усредняя все используемые в его тренировки изображения такого типа. Для получения четкого изображения (пусть, отчасти и с большими потерями в схожести с исходником) была придумана концепция генеративно-состязательных сетей.

**Ключевая идея** заключается в формировании критерия качества для генератора с помощью еще одной НС:

- входной сигнал -> генератор -> сформированное изображение -> нейронная сеть -> значение показателя качества

**РЕАЛИЗАЦИЯ МЕТОДА**

1. Подаем на вход второй НС сгенерированные и реальные изображения вперемешку, она должна будет научиться их различать. Такая сеть получила название **ДИСКРИМИНАТОР**.
   - Пусть она будет выдавать значения float = [0 - 1]
   - 1 - для реальных изобр.
   - 0 - для сгенерированных

2. Для реализации такой сети можно взять критерием ее качества **БИНАРНУЮ КРОСС-ЭНТРОПИЮ**.
   - `loss_dir = -log(real) - log(1 - fake)`
   - Из этой формулы видно, что показатель должен быть минимален для реальных изображений и максимален для сгенерированных.

3. В свою очередь дискриминатор выступает критерием качества для генератора. То есть, генератор должен так построить изображение, чтобы дискриминатор не смог его отличить от реального.
   - Значит, в режиме обучения генератора в бинарной кросс-энтропии требуемый отклик: `tf = 1`
   - `loss_gen = -log(fake)`

Таким образом, здесь получается, что дискриминатор и генератор конкурируют друг с другом и обучаются так, чтобы дискриминатор понимал входы от генератора, а генератор, наоборот, пытается «замаскировать» свою деятельность под реальные изображения.

![27.1. Реализация](2.%20Theory/Машинное%20обучение/Дополнительно/27.1.%20Реализация.md)