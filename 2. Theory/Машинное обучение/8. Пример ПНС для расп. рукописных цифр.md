#theory #theory-ml
 
---
Для распознавания графических образов хорошо себя показали сверточные НС.

Но мы воспользуемся обычной полносвязной П(последовательная)НС с
- 28 x 28 = 784 входами;    - число пикселей изображения
- 128 нейронами скрытого слоя;    - условно / кол-во слоев тоже условно
- 10 нейронами выходного слоя.    - задача классификации (10 цифр)  ф-я активации выходного слоя softmax.

```python
from tensorflow.keras.datasets import mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
# Здесь 60 000 изображений в обучающей выборке и 10 000 – в тестовой 
# (x - изобр. Y - отклик)
# изображение имеет размер 28х28 пикселей по 1 байту(= 8 бит = 2**8 = 25 цветов)

# СТАНДАРТИЗАЦИЯ ВХОДА И ОТКЛИКА ВЫБОРКИ
x_train = x_train / 255
x_test = x_test / 255

y_train_cat = keras.utils.to_categorical(y_train, 10)
y_test_cat = keras.utils.to_categorical(y_test, 10)

# СТРУКТУРА И ТРЕНИРОВКА СЕТИ
model = keras.Sequential([
    Flatten(input_shape=(28, 28, 1)),
    Dense(128, activation='relu'),
    Dense(10, activation='softmax')
])

print(model.summary())

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.fit(x_train, y_train_cat, batch_size=32, epochs=10, validation_split=0.2)

# РАБОТА С ГОТОВОЙ СЕТЬЮ
model.evaluate(x_test, y_test_cat)

n = 1
x = np.expand_dims(x_test[n], axis=0)

print(model.predict(x))
```
