 #theory #theory-ml
 
---
Сети прямого распространения - входной сигнал последовательно проходит через слои сети, и на выходе формируются определенные числовые значения.

Недостатком таких сетей является сложность анализа временных последовательностей, таких как звуковой сигнал, где важно учитывать предыдущие элементы последовательности.

Рекуррентные нейронные сети используются для решения задач, где анализ данных зависит от результатов, полученных на предыдущих шагах.

### Простейшие рекуррентные сети (сеть Джеффа Элмана)

Пример архитектуры:

\[ X rightarrow text{RNN} rightarrow Y ]

где X - входной слой, RNN - рекуррентный слой, Y - выходной слой.

Входной вектор рекуррентного слоя может быть сформулирован как зависимость от текущего входного сигнала \( x(T) \) и предыдущих выходных данных \( Out(T-1) \):

\[ text{input}(T) = f(x(T), Out(T-1)) ]

Начальное значение предыдущего выхода ( Out(0) ) часто устанавливается как вектор нулей.

### Существующие архитектуры сетей

- **Many-to-Many**: формируется выходное значение на каждой итерации рекуррентного слоя.
- **Many-to-One**: формируется одно выходное значение в конце последовательности.
- **One-to-Many**: один входной сигнал генерирует последовательность выходных значений на каждой итерации.
- **One-to-One**: используется для рекуррентных вычислений, где один сигнал приводит к одному выходу в конце алгоритма.

### Backpropagation Through Time (BPTT)

Модифицированный алгоритм обучения для рекуррентных нейронных сетей, который расширяет backpropagation на временные шаги, называется BPTT.

### Нейродинамика

Главная проблема РНС заключается в обеспечении их устойчивости как во время обучения, так и во время работы сети. Научная область, занимающаяся этими вопросами, получила название нейродинамика.

### Литература для изучения

- Саймон Хайкин «Нейронные сети (полный курс)»
