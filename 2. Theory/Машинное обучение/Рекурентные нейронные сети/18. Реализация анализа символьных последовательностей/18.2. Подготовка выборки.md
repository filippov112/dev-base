 #theory #theory-ml
 
---
##### 1. Чтобы было проще решать эту задачу, оставим в тексте только символы русских букв и символы пробела:
```python
	with open('train_data_true', 'r', encoding='utf-8') as f:
	    text = f.read()
	    text = text.replace('\ufeff', '') 		# убираем первый невидимый символ
	    text = re.sub(r'[^А-я ]', '', text) 	# убираем все недопустимые символы

	num_characters = 34 				#33 буквы + пробел
```

##### 2. Создадим обучающую выборку. 
Мы ее будем формировать с помощью инструмента: `tf.keras.preprocessing.text.Tokenizer`, который делает «умный» парсинг (разложение на составляющие элементы) указанного текста. 

Официальная док.:	https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer

- `num_words` – максимальное количество слов (символов), которое вернет Tokenizer (если элементов будет больше, то останутся наиболее повторяющиеся в тексте);
- `filters` 		– исключаемые из текста символы (по умолчанию, следующие: ==!–»—#$%&()*+,-./:;<=>?@[\]^_{|}~\t\n\r);'==
- `lower = True`		– автоматический перевод в нижний регистр для единообразия больших и малых символов;
- `split = '  '` 		– разделение слов по символу пробела;
- `char_level=False` 	– если False, то текст делится на слова, иначе – на символы.

	
```python
tokenizer = Tokenizer(num_words=num_characters, char_level=True)
tokenizer.fit_on_texts(text)				# пропустим загруженный текст через него
print(tokenizer.word_index)					# формируется словарь {' ':1, 'о':2, …}
```

##### 3. Далее, преобразуем текст в набор OHE-векторов:

```python
inp_chars = 3				# число символов для 1 наблюдения
data = tokenizer.texts_to_matrix(text)	# получаем матрицу для всего алфавита
```

##### 4. вычислим размер обучающего множества:
`n = data.shape[0]-inp_chars` - число смещений по алфавиту


##### 5. Сформируем входной тензор и прогнозные значения:
`X = np.array([data[i:i+inp_chars, :] for i in range(n)])`	- входным массивом будет набор из тройных тензоров алфавита до элемента равного числу смещений
`Y = data[inp_chars:]` - выходным массивоом значений будет срез от 4 до последнего тензора алфавита